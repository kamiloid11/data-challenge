
# Мини-ETL для агрегирования по временным окнам и обнаружения аномалий

Проект представляет собой простой ETL‑конвейер для обработки временных рядов, вычисления агрегатов и поиска аномалий. Архитектура модульная, что позволяет изменять конфигурацию, добавлять новые детекторы и подключать различные хранилища данных

## Возможности

- Загрузка данных из CSV
- Трансформация и нормализация набора данных
- Детекторы аномалий: z-score, MAD, rolling; возможна интеграция ML‑детекторов
- Поддержка ClickHouse (через HTTP)
- Система "sinks": вывод в stdout и отправка отчётов в ClickHouse
- Тесты для ключевых компонент

## Установка и запуск

### 1. Установка зависимостей

```
python -m pip install -r requirements.txt
python -m pip install -e .
```

### 2. Поднятие ClickHouse (опционально)

```
docker compose up -d
```

### 3. Запуск pipeline

```
python -m pipeline.runner run --config config/pipeline.yaml
```

Можно указать CSV‑файл вручную:

```
python -m pipeline.runner run --config config/pipeline.yaml --csv path/to/file.csv
```

### 4. Запуск тестов

```
python -m pytest -q
```

## Структура конфигурации

Файл: `config/pipeline.yaml`.

Параметры включают:

- подключение к ClickHouse
- параметры временного окна
- список детекторов
- список sinks (куда отправлять результаты)

Пример:

```
detectors:
  - type: zscore
    threshold: 3.0
  - type: mad
    threshold: 3.5
```

## Расширение функциональности

### Добавление нового детектора

1. Реализовать класс в каталоге `pipeline/detectors/`
2. Зарегистрировать его в фабрике `build_detectors`
3. Настроить параметры в YAML-файле

### Добавление нового sink

1. Реализовать класс sink‑обработчика
2. Добавить его описание в конфиг

## Тестирование

Для запуска автоматических тестов используется:

```
python -m pytest -q
```

## Заметки

- Makefile на Windows не используется. Все команды следует выполнять вручную (см. раздел "Установка и запуск")
- Проект подходит для локального прототипирования, обучения и дальнейшего расширения